---
title: Project-Argus
layout: page
permalink: /project/argus/index.html
---


## Trustworthy Machine Learning from Untrusted Models

<hr>

### Overview


<div align="center"><img src="/assets/images/argus.pdf" alt="argus" height="75%" width="75%" align="middle"/></div>


Many of today's machine learning (ML) systems are not built from scratch, but are "composed" by an array of pre-trained, third-party models. This paradigm shift significantly simplifies the development cycles of ML systems and propels the trend of ML democratization. However, the lack of standardization or regulation for third-party models entails profound security implications. The goal of this project is two-fold: (i) understanding the security vulnerabilities incurred by reusing third-party models as building blocks of ML systems and (ii) developing rigorous yet practical tools to help developers proactively mitigate such threats throughout the lifecycles of ML systems. 

<hr>

### Publications

*  **<font color="purple"> AdvMind: Inferring Adversary Intent of Black-Box Attacks </font>** [[pdf](https://arxiv.org/pdf/2006.09539.pdf)]  <br>
*<font color="black">Ren Pang, Xinyang Zhang, Shouling Ji, Xiapu Luo, Ting Wang</font>* <br>
*<font color="blue">The 26th SIGKDD Conference on Knowledge Discovery and Data Mining (KDD'20)</font>*


*  **<font color="purple"> A Tale of Evil Twins: Adversarial Inputs versus Poisoned Models </font>** [[pdf](https://arxiv.org/pdf/1911.01559.pdf)]  <br>
*<font color="black">Ren Pang, Hua Shen, Xinyang Zhang, Shouling Ji, Yevgeniy Vorobeychik, Xiapu Luo, Alex Liu, Ting Wang</font>* <br>
*<font color="blue">The 27th ACM Conference on Computer and Communications Security (CCS'20)</font>*

*  **<font color="purple">  Text Captcha Is Dead? A Large Scale Deployment and Empirical Study </font>** [[pdf]({{ site.url }}/paper/Shi-ccs-2020.pdf)]  <br>
*<font color="black">Chenghui Shi, Shouling Ji, Qianjun Liu, Changchang Liu, Yuefeng Chen, Yuan He, Zhe Liu, Raheem Beyah,
Ting Wang</font>* <br>
*<font color="blue">The 27th ACM Conference on Computer and Communications Security (CCS'20)</font>*

*  **<font color="purple"> TextShield: Robust Text Classification Based on Multimodal Embedding and Neural Machine Translation </font>** [[pdf]({{ site.url }}/paper/Li-usenix-2020.pdf)]  <br>
*<font color="black">Jinfeng Li, Tianyu Du, Shouling Ji, Rong Zhang, Quan Lu, Min Yang, Ting Wang</font>* <br>
*<font color="blue">The 29th USENIX Security Symposium (SECURITY'20)</font>*

*  **<font color="purple"> Interpretable Deep Learning under Fire </font>** [[pdf](https://arxiv.org/abs/1812.00891)]  <br>
*<font color="black">Xinyang Zhang, Ningfei Wang,  Hua Shen, Shouling Ji, Xiapu Luo, Ting
  Wang</font>* <br>
*<font color="blue">The 29th USENIX Security Symposium (SECURITY'20)</font>*
 
<hr>

### Code & Datasets

* Input-Model Co-Optimization (IMC) Attack [[code](https://github.com/alps-lab/imc)]

<hr>

<img src="/assets/images/nsf.jpg" alt="nsf" height="10%" width="10%" align="absmiddle"/> <img src="/assets/images/nvidia.jpg" alt="nvidia" height="12%" width="12%" align="absmiddle"/> We are grateful for the National Science Foundation (NSF) and Nvidia to support our research.

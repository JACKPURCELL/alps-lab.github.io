---
title: ALPS Lab
layout: page
permalink: /alps/index.html
---


<img src="/assets/images/alps.pdf" alt="alps" height="75%" width="75%"/>

<hr>

### Overview

We are a group of multidisciplinary researchers conducting cutting-edge research on the intersection of machine learning, computational privacy, and cyber-security.

Thanks to the availability of large-scale data sets ("Big Data"), data-driven algorithmic systems (e.g., recommender systems, automated driving vehicles, and personalized healthcare) are playing increasingly important roles in our everyday lives. Our mission is to fully unleash the potential of such systems to support ground-breaking discoveries and critical decision-making. To this end, our research comprises two complementary aspects:
* developing effective, scalable analytical tools to empower such systems
* mitigating their negative impact on individuals and society as a whole, including privacy, security, and accountability issues.

We follow the methodology of "*from practice, to theory and back to practice*". We look to the real world for practical and important problems; then, we design solutions with provable properties and solid theoretical backing; finally, we build and deploy real systems based on these solutions. Our approach is multidisciplinary by nature, using "tools" from  systems, algorithms, machine learning, cryptography, and economics.


<!-- My research focuses on modeling and mining of these dynamic, heterogeneous, and interdependent information sources. Towards this, my efforts involve developing new concepts and principles, designing intelligent algorithms, and building scalable systems. -->


<hr>

### People

I am fortunate to work with a group of wonderful Ph.D. students:

* [Xinyang Zhang](http://www.cse.lehigh.edu/~xizc15)
* [Yujie Ji](http://www.cse.lehigh.edu/~yuj216)
* [Hua Shen](http://hua-shen.org)
* [Ren Pang](http://www.cse.lehigh.edu/~rep218)


Other great student collaborators include:

* Ningfei Wang, M.Sc. student
* Sam Nguyen, M.Sc. student
* Georgi Georgiev, M.Sc. student
* Yifan Huang, Undergrad student

<hr>

### Projects

Following is a list of our ongoing and past projects.


* **<font color="indianred">Attack-Agnostic Defenses against Adversarial Inputs</font>** <br>
Deep learning systems are inherently vulnerable to adversarial inputs, which are maliciously crafted samples to trigger deep neural networks (DNNs) to misbehave, leading to disastrous consequences in security-critical domains. The fundamental challenges of defending against such attacks stem from their adaptive and variable nature: adversarial inputs are tailored to target DNNs, while crafting strategies vary greatly with concrete attacks. In this project, we are building **EagleEye**, a universal, attack-agnostic defense framework that (i) works effectively against unseen attack variants, (ii) preserves the predictive power of DNNs, (iii) complements existing defense mechanisms, and (iv) provides comprehensive diagnosis about potential risks in the system outputs. The project website is [here]({{ site.baseurl }}/project/eagleeye).


* **<font color="indianred">Privacy-Aware Deep Learning of Contextual Knowledge</font>** <br>
Deep learning (DL) technology is envisioned to revolutionize contextual mobile services thanks to its capability of interpreting varied complex data available on mobile devices. However, with the great convenience and opportunities offered by DL-powered contextual services follows the immense threat to user privacy. In this project, we are building **PadLock**, a Privacy-Aware Deep Learning of Contextual Knowledge engine, that facilitates the use of personal information from mobiles while maintaining explicit user control over how such information is used by third-party service providers. The project website is [here]({{ site.baseurl }}/project/padlock).

* **<font color="indianred">Crowd Wisdom in Open World</font>** <br>
Our decisions often rely on others' aggregated judgements, with the belief that the aggregations over a large population can successfully harness the "wisdom of crowds". However, in the open world, individuals are exposed to and "herded" by others' opinions before even forming their own, resulting in biased collective opinions. In this project, we conduct quantitative study on the dynamics underlying the crowd wisdom to answer the fundamental questions: How to characterize this herding effect? How to model its impact on systems that are constantly evolving? How to separate bias incurred by herding effects from genuine opinions? The project website is [here]({{ site.baseurl }}/project/wisdom).

* **<font color="indianred">Privacy-Aware Personalized Assistant for Healthcare Q&A </font>** <br>
Today, over one-third of Americans rely on online health forums (OHFs) to search and retrieve halthcare information. Compared with the increasing popularity of OHFs, the progress in their supporting platforms is lagging way behind. Built upon the traditional question-and-answer (Q&A) paradigm, todayâ€™s OHFs suffer two major issues: privacy vulnerability and Q&A inefficacy. In this project, we are building **Papaya**, a personalized assistance tool that guides ordinary users to perform effective and privacy-preserving information seeking and providing on OHFs. The project website is [here]({{ site.baseurl }}/project/papaya).

<!-- * **<font color="indianred">Trustworthy Machine Learning from Untrusted Models</font>** <br> -->
